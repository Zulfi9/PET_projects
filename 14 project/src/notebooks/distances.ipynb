{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открой файл [distances.ipynb](src/notebooks/distances.ipynb). \n",
    "* Объедини общие данные о фильмах [tmdb_5000_movies](https://files.sberdisk.ru/s/te4QbzdxKgsFQXA) и каст фильмов \n",
    "[tmdb_5000_credits](https://files.sberdisk.ru/s/H9oRuXQt5mFz3T9). \n",
    "* Оставь в датасете только фильмы, которые вышли в \"релиз\".\n",
    "* Убери фильмы с пропусками в колонках ['overview', 'genres', 'keywords']\n",
    "* Выведи количество фильмов, оставшихся в выборке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество фильмов, оставшихся в выборке = 4792\n"
     ]
    }
   ],
   "source": [
    "# Создаем датафремы из csv файлов\n",
    "df_movies = pd.read_csv('../../datasets/tmdb_5000_movies.csv')\n",
    "df_credits = pd.read_csv('../../datasets/tmdb_5000_credits.csv')\n",
    "\n",
    "# Объединяем датафреймы в один, причем movies слева и объединение по столбцу id, credits справа и объединение по столбцу movie_id\n",
    "df = pd.merge(df_movies, df_credits, how='left', left_on='id', right_on='movie_id')\n",
    "\n",
    "# Оставим в датафреймы только те фильмы, которые вышли в релиз\n",
    "df = df[df['status'] == 'Released']\n",
    "\n",
    "# Убираем фильмы с пропусками в колонках ['overview', 'genres', 'keywords']\n",
    "df = df.dropna(subset =['overview'])\n",
    "df = df.dropna(subset =['genres'])\n",
    "df = df.dropna(subset =['keywords'])\n",
    "\n",
    "print('Количество фильмов, оставшихся в выборке =', df.shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем алгоритм рекомендации на основе описания фильма (`overview`) и ключевых слов к фильму (`keywords`). \n",
    "Объедини тексты этих колонок и проведи предобработку:\n",
    "* Замени NaN в описании фильма на пустой символ `''`\n",
    "* Удали все английские стоп-слова (используй параметр `stop_words` в `TfidfVectorizer`)\n",
    "* Рассчитай матрицу [Tf-Idf](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) для описания фильмов.\n",
    "\n",
    "Выведи размер получившейся матрицы\n",
    "> Параметр `max_features` в `TfidfVectorizer` должен быть равен 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    In the 22nd century, a paraplegic Marine is di...\n",
       "1    Captain Barbossa, long believed to be dead, ha...\n",
       "2    A cryptic message from Bond’s past sends him o...\n",
       "3    Following the death of District Attorney Harve...\n",
       "4    John Carter is a war-weary, former military ca...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединим тексты колонок в одну\n",
    "df['overview'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...\n",
       "1    [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...\n",
       "2    [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...\n",
       "3    [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...\n",
       "4    [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keywords'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       In the 22nd century, a paraplegic Marine is di...\n",
       "1       Captain Barbossa, long believed to be dead, ha...\n",
       "2       A cryptic message from Bond’s past sends him o...\n",
       "3       Following the death of District Attorney Harve...\n",
       "4       John Carter is a war-weary, former military ca...\n",
       "                              ...                        \n",
       "4798    El Mariachi just wants to play his guitar and ...\n",
       "4799    A newlywed couple's honeymoon is upended by th...\n",
       "4800    \"Signed, Sealed, Delivered\" introduces a dedic...\n",
       "4801    When ambitious New York attorney Sam is sent t...\n",
       "4802    Ever since the second grade when he first saw ...\n",
       "Name: overview_and_keywords, Length: 4792, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overview_and_keywords'] = df['overview'] + df['keywords']\n",
    "df['overview_and_keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер получившейся матрицы Tf-Idf (4792, 10000)\n"
     ]
    }
   ],
   "source": [
    "vector = TfidfVectorizer(stop_words='english', max_features= 10000)  # создаем матрицу функций, удаляя все английские слова\n",
    "df['overview'] = df['overview'].fillna('')  # заменяем NaN в описании фильма на пустой символ \"\"\n",
    "matrix = vector.fit_transform(df.overview)  # создаем матрицу TF-Idf\n",
    "print ('Размер получившейся матрицы Tf-Idf', matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитай [cosine similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) \n",
    "между фильмами. Составь из этой матрицы `pd.DataFrame`. Для дальнейшего удобства, \n",
    "колонки и индексы таблицы назови согласно`id` фильма. \\\n",
    "Сохрани получившийся `DataFrame` c расстояниями в папку [assets](src/assets) с названием `distance.csv`.\n",
    "А сам объединенный датасет с фильмами сохрани в папку [assets](src/assets) с названием `movies.csv`.\n",
    "\n",
    "> Получившиеся файлы `distance.csv` и `movies.csv` пушить в GitLab не нужно!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(matrix)\n",
    "# df_distance = pd.DataFrame(cosine_sim, index = df.id, columns = df.id)\n",
    "df_distance = pd.DataFrame(cosine_sim, index = df['id'], columns = df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distance.to_csv('../assets/distance.csv')\n",
    "df.to_csv('../assets/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
