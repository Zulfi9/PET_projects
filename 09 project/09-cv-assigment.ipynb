{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc96ecfa-5d52-47b6-a976-ed8920ea2c91",
   "metadata": {},
   "source": [
    "# Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1ae31",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a00d3",
   "metadata": {},
   "source": [
    "Давай загрузим датасет CIFAR-10. Допиши функцию [load_dataloaders](./code-samples/cv_utils.py) с помощью [torchvision.datasets.CIFAR10](https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html)\n",
    "и [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), чтобы функция возвращала\n",
    "DataLoaderы для train и test частей датасета. \\\n",
    "C помощью функции `len` количество батчей в train_loader и test_loader.\n",
    "> Для DataLoader параметры `transform` и `batch_size` оставьте по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb63e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_TRANSFORM = transforms.Compose(\n",
    "    [\n",
    "        # Перевод изображений в тензоры\n",
    "        transforms.ToTensor(),\n",
    "        # Переводим цвета пикселей в отрезок [-1, 1]\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "BATCH_SIZE = 64 # Количество изображений в Батче\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # Классы CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7113c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloaders(transform=BASE_TRANSFORM, batch_size=BATCH_SIZE):\n",
    "    train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # test_set = Код тут\n",
    "    # test_loader = Код тут\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f876e",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a5ac9",
   "metadata": {},
   "source": [
    "Узнай, как из объекта DataLoader можно получить изображения и метки. \\\n",
    "Передай первые 4 изображения и метки из первого батча тестовой выборки в функцию [imshow](./code-samples/cv_utils.py).\n",
    "С помощью нее можно визуализировать датасет. \\\n",
    "Должна получиться примерно такая визуализация.\n",
    "![sample](../misc/images/images_sample.png)\n",
    "> Картинки и метки могут отличаться. Главное чтобы метки сходились с изображениями)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a9831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(images, labels, padding_size=15, labels_split_size=25):\n",
    "    # убрать нормализацию\n",
    "    img = img / 2 + 0.5    \n",
    "    npimg = img.numpy()\n",
    "    label_text = (' ' * labels_split_size).join('{}'.format(CLASSES[j]) for j in labels.tolist())\n",
    "    print(' ' * padding_size + label_text)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b603c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed667eb",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96195e2f",
   "metadata": {},
   "source": [
    "Теперь попробуем написать небольшую сверточную нейронную сеть, которую мы будем обучать классифицировать изображения.\n",
    "\n",
    "Напишем сеть, основанную на одном блоке архитектуры [ResNet](https://arxiv.org/pdf/1512.03385.pdf) - Residual-Block. Схема этого блока приведена ниже:\n",
    "\n",
    "<img src=\"../misc/images/rediual_block.png\" width=\"500\"/>\n",
    "\n",
    "Допишите класс ResidualNet:\n",
    "- Все сверточные слои должны иметь 32 выходных канала, а также не должны изменять ширину и высоту изображения.\n",
    "- Также в сверточных слоях `padding = 1`\n",
    "\n",
    "Функции, которые вам понадобяться: \n",
    "[Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), [BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html), [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html).\n",
    "\n",
    "Для базовой проверки, что сеть написана верно этот код не должен выдавать ошибку\\\n",
    "`assert net(torch.zeros((10, 3, 32, 32))).shape == (10, 10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b15b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualNet(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_3 = nn.Conv2d(3, 32, 1)\n",
    "\n",
    "        self.residual_block = nn.Sequential( \n",
    "            # Код тут\n",
    "        )\n",
    "\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(8),\n",
    "            nn.Flatten(1),\n",
    "            nn.Linear(512, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.residual_block(x)\n",
    "        out += self.conv_3(x)\n",
    "        out = self.clf(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0278b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0644d4",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c786c99",
   "metadata": {},
   "source": [
    "Перейдем к обучению сети. В этом вам поможет класс [Trainer](./code-samples/cv_utils.py).\\\n",
    "Для обучения кроме самой модели \n",
    "требуемся определить оптимизатор и функцию ошибок:\n",
    "* В качестве оптимизатора выберите [стохастический градиентный спуск](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n",
    "* В качестве функции ошибок\n",
    "[кросс-энтропия](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
    "\n",
    "Обучите сеть и с помощью функции [plot_train_log](./code-samples/cv_utils.py) визуализируй процесс обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c46945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, optimizer, criterion):\n",
    "        self.model = model\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.model.to(self.device)\n",
    "        print('Сеть загружена на', self.device)\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def _train_epoch(self, train_loader):\n",
    "        loss_log = []\n",
    "        acc_log = []\n",
    "        self.model.train()\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data = data.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            logits = self.model(data)\n",
    "\n",
    "            loss = self.criterion(logits, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            loss_log.append(loss.item() * data.shape[0])\n",
    "\n",
    "            acc = (logits.argmax(dim=1) == target).sum()\n",
    "            acc_log.append(acc.item() / data.shape[0]) \n",
    "\n",
    "        return np.mean(loss_log), np.mean(acc_log)\n",
    "\n",
    "    def train(self, train_loader, test_loader, n_epochs):\n",
    "        \n",
    "        self.train_loss_log = [] \n",
    "        self.train_acc_log = [] \n",
    "        self.test_loss_log = []\n",
    "        self.test_acc_log = []\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss, train_acc = self._train_epoch(train_loader)\n",
    "            test_loss, test_acc = self.test(test_loader)\n",
    "\n",
    "            self.train_loss_log.append(train_loss)\n",
    "            self.train_acc_log.append(train_acc)\n",
    "\n",
    "            self.test_loss_log.append(test_loss)\n",
    "            self.test_acc_log.append(test_acc)\n",
    "\n",
    "            print(f\"Epoch {epoch}\")\n",
    "            print(f\" train loss: {np.mean(train_loss)}, train acc: {np.mean(train_acc)}\")\n",
    "            print(f\" test loss: {test_loss}, test acc: {test_acc}\\n\")\n",
    "    \n",
    "    def test(self, test_loader):\n",
    "        loss_log = []\n",
    "        acc_log = []\n",
    "        self.model.eval()\n",
    "\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(data)\n",
    "                loss = self.criterion(logits, target)\n",
    "\n",
    "            loss_log.append(loss.item() * data.shape[0])\n",
    "\n",
    "            acc = (logits.argmax(dim=1) == target).sum()\n",
    "            acc_log.append(acc.item() / data.shape[0]) \n",
    "\n",
    "        return np.mean(loss_log), np.mean(acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2821c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_log(trainer):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "    axs[0].plot(range(1, len(trainer.train_loss_log) + 1), trainer.train_loss_log, label='train')\n",
    "    axs[0].plot(range(1, len(trainer.test_loss_log) + 1), trainer.test_loss_log, label='test')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "\n",
    "    axs[1].plot(range(1, len(trainer.train_acc_log) + 1), trainer.train_acc_log, label='train')\n",
    "    axs[1].plot(range(1, len(trainer.test_acc_log) + 1), trainer.test_acc_log, label='test')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d49690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8618e9",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80738a0e",
   "metadata": {},
   "source": [
    "Одной стандартной техникой, применяющейся в глубинном обучении, а особенно часто в компьютерном зрении, являются аугментации данных. \\\n",
    "Суть аугментаций состоит в том, что мы можем некоторым синтетическим образом видоизменять объекты обучающей выборки,  тем самым расширяя ее, а также делая итоговую модель более устойчивой к таким изменениям.\n",
    "Наиболее удобным способом работы с аугментациями в PyTorch является их задание в списке `transforms`, который затем передается в Dataloader.\\\n",
    "Изучи, какие [способы аугментаций](https://pytorch.org/vision/main/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) \n",
    "изображений можно использовать PyTorch. Выберите несколько из них и визуализируйте как изменился датасет. \n",
    "![sample](../misc/images/images_sample.png)\n",
    "![sample](../misc/images/augment.png)\n",
    "\n",
    "Обучите сеть с аугментацией данных и с помощью функции [plot_train_log](./code-samples/cv_utils.py) визуализируй процесс обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e99cfacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_v2 = transforms.Compose(\n",
    "        [\n",
    "            # Код тут\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
